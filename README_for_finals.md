# 上帝说要有光 团队方案


## 方法模型设计/改进思路

Panoptic Scene Graph Generation 任务在全景分割的基础上，需要为其中具有位置、语义关系的两个“实体”（或者说是“staff”）进行“关系”的建模。我们认为，主、宾实体的检测，与关系的建立是两大核心步骤，并且前者很大程度上决定了后者的召回上限。

在本次比赛中，我们将主、宾实体的检测与关系的建立进行二阶段训练。
相比于一阶段端到端的训练方案，二阶段方案由于在关系GT的匹配上不需要使用匈牙利匹配，训练过程更加稳定，且全景分割的精度更高。

全景分割部分我们复用了[mask2former](https://github.com/open-mmlab/mmdetection/tree/master/configs/mask2former)方案及其训练策略，
得益于其准确的分割精度，为后续关系中主宾实体的召回提供了强有力的保证。此外，PSG任务重很多“关系”类别对两个实体的边缘建模及其敏感，例如“biting”，“lying on”等，
相比实体内部，实体边缘至关重要，我们增加了边缘loss希望进一步生提升整体精度。

在获得每个实体的 mask 后，依据 mask 为每一个实体划分成 L 个 token，并额外增加一个 cls token，随后所有实体的 $N * (L+1)$ 个token送入 transformer 进行全局建模，得到 $[bs, N*(L+1), 768]$ 维张量。 然后在实体粒度上进行全局池化，将一个实体的多个 token 收紧为 1 个token，得到 $[bs, N, 768]$ 维张量。

得到实体级别 embedding 后，只需用对应的 embedding 建模任意两个 token 的关系即可。
同样是对任意两个 token 的关系进行建模，[GlobalPointer](https://kexue.fm/archives/8373) 给出了非常优秀的解决方案。
GlobalPointer 是为解决 NLP 任务中“实体抽取”问题提出的方案。
它将两两关系的建模直接使用 self-attention 实现，不仅将嵌套问题离散化，而且精度、速度均有提升。
本质上是 Multi-Head Attention 的一个简化版，有多少种实体就对应多少个head，相比 Multi-Head Attention 去掉了 V 相关的运算。
我们借鉴 GlobalPointer 方法，通过 self-attention layer 实现两两实体关系的建模。
有多少个类，计算 attention 的 head 就设成多少。
通过这样的设计，我们把一个多分类任务变成了一个多标签任务，除了在infer阶段可以充分对关系进行召回的同时，在train阶段还可以完美解决“相同主宾具有多个谓语”的情况，从而保证训练过程的稳定和精度的进一步提升。


> 可能有读者会问：这种设计的复杂度明明就是 $O(n^{2})$ 呀，不会特别慢吗？如果现在还是RNN/CNN的时代，那么它可能就显得很慢了，但如今是 Transformer 遍布的时代，Transformer的每一层都是 $O(n^{2})$ 的复杂度，多GlobalPointer一层不多，少GlobalPointer一层也不少，关键是 $O(n^{2})$ 的复杂度仅仅是空间复杂度，如果并行性能好的话，时间复杂度甚至可以降到 $O(n)$，所以不会有明显感知。

模型整体结构如下：

<div align=center>
<img src="./imgs/mfpsg_model.jpg" width = "550" />
</div>







（from 比赛官网）全场景图生成作为一个建立在传统检测分割任务上的新的上层任务，是一个非常有挑战的视觉任务，有以下几个难点有待参赛者解决。
1. **问题抽象程度高**：

> **关系的模糊性**：有一些关系的意思难以被准确定义。例如 crossing 可以使用在airplane crossing sky, car crossing road，person crossing road。模型需要学习到“穿过”这种模糊关系的含义。

> **关系的相似性**：一些关系和其他关系的差异不显著。例如 running 和 walking，有 parked on 和 driving on。模型需要通过一些视觉细节来做出选择。

> **关系的准确性**：我们在标注测试集时要求标注员能标更准确的关系（例如 walking on）就不标注更模糊的关系（例如 on）。这就要求模型不能简单地预测模糊的关系，而要更加注重对图中关系的准确描述。

+ **应对/解决方案**

对**抽象问题**的建模正是神经网络+e2e训练的优势，这需要神经网络充分理解原始输入，才有可能真正的学习到其中的“抽象”问题。
一些关系的定义本身就是模凌两可的，在人类的语义上，多多少少存在一些重叠，这导致了**关系的模糊性**与**关系的相似性**，此外由于

> **关系的准确性**：我们在标注测试集时要求标注员能标更准确的关系（例如 walking on）就不标注更模糊的关系（例如 on）

意味着确实可能存在一些具有包含、重叠关系的多个标签最终只留下单一标签，这在训练阶段会导致loss收敛困难，模型难以更新到最佳状态。

首先我们确定了这一问题，在对实验结果的分析中发现，具有10余对关系（在模型角度看来）是高度相似的，其中一个关系的激活值很高时，其对应的相似关系的激活值也不会很低。
为了缓解**关系的模糊性**、**关系的相似性**与**关系的准确性**问题对模型造成的影响，我们将关系的多分类问题变成了一个多标签问题，即上面提到过的使用 self-attention 输出每个类别的激活值。这时，任务变成了一个 missing label 的多标签问题，为了解决这一问题，我们对原始训练数据进行了关系标签的重构，通过再次输出训练数据的激活值，将 one-hot 形式的 label 变成 soft label，再次进行微调。


2、数据复杂度高：

> **长尾效应**：根据真实世界的数据分布，本任务提供的数据有天然的长尾效应。具体上讲，长尾效应同时表现在关系和物体/背景类别上。解决长尾问题可有效提升 mean recall @ 20 这个评价指标。

> **不准确的分割标注**：本任务提供的数据集基于 coco 全景分割。分割中存在分割标注不准确，漏标的问题。参赛者需要考虑如何避免噪声标注的影响。

> **三元组的不完全标注**：本任务的训练集并不是完全标注，即有一些图片的部分关系没有标出。参赛者需要考虑处理这类不完全标注的问题。

+ **应对/解决方案**

真实世界中基本都存在着长尾效应，由于我们将关系的多分类问题转化成了多标签问题，长尾效应出现在两个维度上，“类别维度长尾效应”和“正负样本长尾效应”。
处理“类别维度长尾效应”时，我们采用了自适应类别权重方案，将56个类别看成56个独立样本，通过56个样本的loss对原来的56个类别进行了加权。
处理“正负样本长尾效应”时，我们采用了经典的focal loss，同样通过正负样本的loss进行加权。

坦白的说，**不准确的分割标注** 这个问题没有没有找到有效的处理方案。coco标注的mask虽然比较粗糙，但是一些研究发现模型行之有效的训练及边缘loss，可以使模型自动聚焦到边缘部分。如下图所示，第一行为加入了边缘优化的模型输出mask，第二行为coco原始标注的mask，我们认为并不十分完美的标注并不会为模型性能带来显著差异。

![img](./imgs/WX20221120-144300%402x.png)

由于我们在上面重构了原始训练数据的关系标签，在将 one-hot 形式的 label 变成 soft label的同时对训练数据中缺失标注的部分进行了伪标签的补全，有效缓解了**三元组的不完全标注**问题。


3、算法复杂度高：

> **对算法速度的要求**: 如果算法先检测物体后再预测关系，假设检测出了n个物体，两两比较关系需要进行 n × (n-1) 比较，这会让推断速度很慢，不利于实际生产。任务要求设计的算法有较快的速度。

> **关注远距离物体之间的关系**：有时图片上的关系出现在两个较远的物体之间。算法需要处理远距离物体之间的关系。

> **关系的层级结构**：关系大体可以分成位置关系和动作关系。算法可能需要对关系的层级结构进行建模，以避免对一个种类的关系的忽视。

> **利用视觉推理进行关系识别**：算法可能需要利用视觉推理进行关系识别，这是目前计算机视觉领域尚未全面探索的领域。

> **避免算法误入捷径**：模型在预测关系时容易走捷径。这包括模型会不根据图片的实际内容，而只根据分割出的物体类别预测高频关系（如检测到 person 和 bicycle就认为一定是riding，然而图片实际是 person carrying bicycle），或倾向于输出简单关系。算法需要规避这一点

可能导致上述几个问题的原因都是模型算法没有对图像中主宾实体进行充分的建模，例如两个实体关系较远、两个实体关系可能与背景有关即一个关系的判定可能涉及多个实体、主宾关系过拟合导致算法误入捷径。我们的解决方案是从全局建模出发，在预测两两关系之前，每个实体需要同所有的实体一同进入transformer建模。这样可以完全避免主宾关系过远的问题，还可以完全有效解决多个实体决定一个关系的问题。同时，由于共同建模阶段存在大量噪声token，可以有效的缓解主宾关系过拟合。

得益于transformer强大的建模与并行能力，我们的base单模型可以实现单张图像在(800, 1333)尺度下全流程(包含resize、infer、后处理等) $0.36\pm0.02$ 秒的推理推理，且在精度上具有[显著优势](https://www.cvmart.net/race/10349/rank)

<div align=center>
 <img src="./imgs/WX20221118-110559%402x.png" width = "480"  alt=""/> <img src="./imgs/WX20221118-111022%402x.png" width = "500"  alt=""/>
 </div>



## 实现细节
全景分割部分采用开源的[Mask2Former](https://github.com/open-mmlab/mmdetection/tree/master/configs/mask2former)预训练方案与权重，
transformer 部分采用开源的[transformers](https://github.com/huggingface/transformers)




## 训练流程
```bash
# 8卡训练
bash tools/dist_train.sh configs/psg/submit_cfg.py 8 
```
更多环境安装、训练、推理细节可[参阅](./README.md)


## 对模型性能有影响的训练/推理策略
除了在第一部分提到的idea外，以下trick对训练或推理也有积极的效果。

+ #### 关系建模 Query、Key-size
在关系建模的 self-attention 部分，query 和 key 的 size 可以适当调大。经过消融实验，1024的参数效果最好。为了节省现存开销，比赛方案使用了512的size。

+ #### 常规的数据增强
常规的数据增强可以提升全景分割、R20和mR20的精度

+ #### Transformer
关系部分的建模使用到了 transformer 模型，经过多个消融实验，显示使用 [hfl/chinese-roberta-wwm-ext](https://huggingface.co/hfl/chinese-roberta-wwm-ext?text=%E7%94%9F%E6%B4%BB%E7%9A%84%E7%9C%9F%E8%B0%9B%E6%98%AF%5BMASK%5D%E3%80%82) 的前2层精度最高。

+ #### 置信度连乘

最终输出的关系 predict 不仅与关系模型的输出相关，而且与 mask 精度呈现正相关。
```python
最终输出的分数 = 主语 mask 置信度 * 谓语关系置信度 * 宾语 mask 置信度
```
可以提高模型精度

+ #### Mask抖动

在训练阶段，只有gt的mask，非常准确。但在infer阶段，会出现大量置信度很低的mask，由此会造成训练-推理阶段的差异。为此，在训练阶段，对于mask进行小幅度膨胀、腐蚀的增强，此外随机生成一些假的mask作为负样本。在不增加任何推理成本的情况下，可提升模型精度

+ #### 多标签分类loss

关系的预测本质上是一个多标签问题，存在 N 个实体的情况下，需要对 ```56 * N * N``` 个预测值进行监督，一般来说，真正“有关系”的正样本对不会超过20个，即存在极其严重的类别不均衡问题。为了解决这一问题，我们借鉴了[将“softmax+交叉熵”推广到多标签分类问题](https://kexue.fm/archives/7359)的方法，显著提升了训练稳定性和精度

+ #### Focal loss
focal loss 可以进一步缓解长尾问题，精度小幅度提升